@misc{soundfile,
title = {SoundFile can read and write sound files and manipulate their data},
author = {Bechtold, Bastian},
year = {2013},
url = {https://pysoundfile.readthedocs.io/en/latest/}
}

@misc{ffmpeg,
  title={A complete, cross-platform solution to record, convert and stream audio and video.},
  author={Bellard, Fabrice},
  year={2006},
  url = {https://ffmpeg.org/}
}

@misc{pytz,
title = {Current and historical timezone database for Python},
author = {Bishop, Stuart},
year = {2004},
url = {https://pypi.org/project/pytz/#description}
}

@ARTICLE{Budka2023,
author={Budka, Micha{\l}
and Soko{\l}owska, Emilia
and Muszy{\'{n}}ska, Adrianna
and Staniewicz, Agata},
title={Acoustic indices estimate breeding bird species richness with daily and seasonally variable effectiveness in lowland temperate Bia{\l}owie{\.{z}}a forest},
journal={Ecological Indicators},
year={2023},
month={Apr},
day={01},
volume={148},
pages={110027},
keywords={Acoustic indices; Acoustic monitoring; Autonomous sound recorder; Biodiversity monitoring; Bird species richness; Forest; Passive acoustic monitoring; Temperate region},
abstract={Acoustic indices have been proposed as rapid and easy to apply tool for biodiversity estimation of vocalising animals without the need for individual species identification. However, inconclusive, or even opposite dependencies between acoustic indices and animal biodiversity found in various studies suggest that their effectiveness is environmentally variable. Here we examined how three acoustic indices: Bioacoustic Index (BI), Acoustic Complexity Index (ACI) and Acoustic Diversity Index (ADI) predict bird species richness in a species-rich, lowland temperate forest in Europe -- the Bia{\l}owie{\.{z}}a Forest. We recorded soundscape in early and late spring at 84 recording points. We analysed 72 1-min sound samples collected per recording point to evaluate how well acoustic indices predict bird species richness from the perspective of a single sound sample, survey and recording point and how they follow the daily pattern of singing activity. When we compared the values of acoustic indices with the number of bird species detected manually in 1-min sound samples, we found BI to best predict the bird species richness, independently of time in the season but variably across the day, while ACI and ADI showed weaker dependency, variable both seasonally and daily. The correlation between each index and number of bird species was stronger in the early part of the season. Averaged by survey or recording point, the acoustic indices correlated more strongly with the mean compared to the total bird species richness, and provided better estimation of bird biodiversity in the early than the late survey. At the level of the recording point, BI correlated most strongly with mean bird species richness (rho = 0.584), while ADI correlated most strongly with total bird species richness (rho = -0.347). Acoustic indices followed daily bird activity pattern, yet they provided greater values before the peak of the species richness estimated by manual spectrogram scanning and listening to recordings. In this study acoustic indices correlated moderately to strongly with the bird species richness, providing a useful tool for rapid estimation of bird biodiversity in temperate forests. However, daily and seasonal variation in effectiveness of acoustic indices should be taken into account in the analysis. Using the mean instead of the total number of bird species in comparisons improved the effectiveness of indices but measured different aspects of biodiversity.},
issn={1470-160X},
url={https://www.sciencedirect.com/science/article/pii/S1470160X23001693}
}

@ARTICLE{Campos2021,
author={Campos, Ivan Braga
and Fewster, Rachel
and Truskinger, Anthony
and Towsey, Michael
and Roe, Paul
and Vasques Filho, Demival
and Lee, William
and Gaskett, Anne},
title={Assessing the potential of acoustic indices for protected area monitoring in the Serra do Cip{\'o} National Park, Brazil},
journal={Ecological Indicators},
year={2021},
month={Jan},
day={01},
volume={120},
pages={106953},
keywords={Bioacoustics; Ecoacoustics; Acoustic indices; Acoustic region; Monitoring; Protected areas; National park},
abstract={Protected areas (PAs) monitoring is a technical bottleneck that limits the implementation of decision-making processes for natural resource and wildlife management. Recent methodological advances make passive acoustic monitoring and associated acoustic index analysis an increasingly suitable method for PAs monitoring. Acoustic indices are mathematical filters that can provide standardised comparative information about the acoustic energy, which can be applied to compare communities. In this study we test whether acoustic indices are sufficiently sensitive to detect differences in the soundscape within each of the four seasons between a PA (the Serra do Cip{\'o} National Park, Brazil) and a surrounding farmland area. Statistical analysis of results from 12 acoustic indices is used to identify which of 20 acoustic regions, defined by frequency range and time period, present the greatest differences between the two sites. The soundscapes of the two sites differed most in autumn within the acoustic region 6, representing 05:30 -- 09:00am and a range of 0.988--3.609 kHz. This acoustic region exhibited significant differences for all the 12 indices tested. Visual examination of 65 long-duration false-colour (LDFC) spectrograms resulted in the selection of 865 (from 1365) sound files with acoustic events within the range of acoustic region 6. Sonotype analysis of the 865 files showed that the soundscape outside the park is strongly influenced by human activity, with domestic animals rare in the park soundscape (1{\%} of the sound files), but very common in the surrounding farmland environment (63{\%} of the sound files). The main goal of monitoring programmes detecting biodiversity trends across space and time, which is here achieved via passive acoustic monitoring and acoustic indices. This confirms the utility of the techniques used here for PA monitoring, especially for detecting trends in anthropogenic disturbance, which is a common threat to natural habitats in parks and reserves in the tropics.},
issn={1470-160X},
url={https://www.sciencedirect.com/science/article/pii/S1470160X2030892X}
}

@ARTICLE{harris2020,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@misc{astral,
title = {Package for calculating the times of various aspects of the sun and moon},
author = {Kennedy, Simon},
year = {2009},
url = {https://astral.readthedocs.io/en/latest/}
}  

@ARTICLE{Morgan2021,
author={Morgan, M. M.
and Braasch, J.},
title={Long-term deep learning-facilitated environmental acoustic monitoring in the Capital Region of New York State},
journal={Ecological Informatics},
year={2021},
month={Mar},
day={01},
volume={61},
pages={101242},
keywords={Acoustic environment; Deep learning; Biophony; Passive acoustic monitoring},
abstract={The effect of anthropogenic activity on animal communication is of increasing ecological concern. Passive acoustic recording offers a robust, minimally disruptive, long-term approach to monitoring species interactions, particularly because many indicator species of environmental health factors such as biodiversity, habitat quality, and pollution produce distinct vocalizations. Machine learning algorithms have been used in recent decades to automatically analyze the large quantities of audio data that result. In this study, a microphone array was used to collect continuous audio data at a site in the Capital Region of New York State for twelve months, resulting in over 8000 h of recordings. A 19-class database containing a variety of bio- and anthrophony was used to train a convolutional neural network in order to generate a reliable record of species-specific calling activity for the entire study period. These results were used to calculate an acoustics-based pseudo-species richness and abundance distribution. Additionally, heatmap plots were used to visualize (i) the time of day (x), sound category (y), and predicted number of sonic events for an average 30-day period and (ii) the day of the year (x), time of day (y), and predicted number of sonic events for each sound category. The correlations between these sonic events and various abiotic factors such as number of daylight hours, temperature, and weather activity were also examined.},
issn={1574-9541},
url={https://www.sciencedirect.com/science/article/pii/S1574954121000339}
}

@misc{SoX,
title = {SoX - Sound eXchange, the Swiss Army knife of audio manipulation},
author = {Norskog, Lance},
year = {1991},
url = {http://sox.sourceforge.net/}
}

@misc{Prince2019,
author={Prince, Peter
and Hill, Andrew
and Pi{\~{n}}a Covarrubias, Evelyn
and Doncaster, Patrick
and Snaddon, Jake L.
and Rogers, Alex},
title={Deploying Acoustic Detection Algorithms on Low-Cost, Open-Source Acoustic Sensors for Environmental Monitoring},
year={2019},
volume={19},
number={3},
keywords={acoustics; bioacoustics; ecology; conservation; machine learning},
abstract={Conservation researchers require low-cost access to acoustic monitoring technology. However, affordable tools are often constrained to short-term studies due to high energy consumption and limited storage. To enable long-term monitoring, energy and space efficiency must be improved on such tools. This paper describes the development and deployment of three acoustic detection algorithms that reduce the power and storage requirements of acoustic monitoring on affordable, open-source hardware. The algorithms aim to detect bat echolocation, to search for evidence of an endangered cicada species, and also to collect evidence of poaching in a protected nature reserve. The algorithms are designed to run on AudioMoth: a low-cost, open-source acoustic monitoring device, developed by the authors and widely adopted by the conservation community. Each algorithm addresses a detection task of increasing complexity, implementing extra analytical steps to account for environmental conditions such as wind, analysing samples multiple times to prevent missed events, and incorporating a hidden Markov model for sample classification in both the time and frequency domain. For each algorithm, we report on real-world deployments carried out with partner organisations and also benchmark the hidden Markov model against a convolutional neural network, a deep-learning technique commonly used for acoustics. The deployments demonstrate how acoustic detection algorithms extend the use of low-cost, open-source hardware and facilitate a new avenue for conservation researchers to perform large-scale monitoring.},
issn={1424-8220},
doi={10.3390/s19030553},
url={https://doi.org/10.3390/s19030553}
}

@ARTICLE{Roe2021,
author={Roe, Paul
and Eichinski, Philip
and Fuller, Richard A.
and McDonald, Paul G.
and Schwarzkopf, Lin
and Towsey, Michael
and Truskinger, Anthony
and Tucker, David
and Watson, David M.},
title={The Australian Acoustic Observatory},
journal={Methods in Ecology and Evolution},
year={2021},
month={Oct},
day={01},
publisher={John Wiley {\&} Sons, Ltd},
volume={12},
number={10},
pages={1802-1808},
keywords={acoustics; big data; ecological monitoring; sensors},
abstract={Abstract Fauna surveys are traditionally manual, and hence limited in scale, expensive and labour-intensive. Low-cost hardware and storage mean that acoustic recording now has the potential to efficiently build scale in terrestrial fauna surveys, both spatially and temporally. With this aim, we have constructed the Australian Acoustic Observatory. It provides a direct and permanent record of terrestrial soundscapes through continuous recording across Australian ecoregions, including those periodically subject to fire and flood, when manual surveys are dangerous or impossible. The observatory comprises 360 permanent listening stations deployed across Australia. Groups of four sensors are deployed at each of 90 sites, placed strategically across ecoregions, to provide representative datasets of soundscapes. Each station continuously records sound, resulting in year-round data collection. All data are made freely available under an open access licence. The Australian Acoustic Observatory is the world's first terrestrial acoustic observatory of this size. It provides continental-scale environmental monitoring of unparalleled spatial extent, temporal resolution and archival stability. It enables new approaches to understanding ecosystems, long-term environmental change, data visualization and acoustic science that will only increase in scientific value over time, particularly as others replicate the design in other parts of the world.},
issn={2041-210X},
doi={10.1111/2041-210X.13660},
url={https://doi.org/10.1111/2041-210X.13660}
}

@misc{Sonobat,
title = {The benefits of full-spectrum data for analyzing bat echolocation calls},
author = {Szewczak, Joe},
year = {2023},
url = {https://www.sonobat.com/}
} 

@misc{emu,
  author = {Truskinger,  Anthony and MacAskill,  Noah and {JordanMercerECCC} and Scarpelli,  Marina D. A.},
  title = {QutEcoacoustics/emu: Support for AudioMoth CONFIG.TXT files improved},
  publisher = {Zenodo},
  year = {2023},
  copyright = {Open Access},
  url = {https://doi.org/10.5281/zenodo.8093028}
}

@ARTICLE{Wimmer2013,
author={Wimmer, Jason
and Towsey, Michael
and Roe, Paul
and Williamson, Ian},
title={Sampling environmental acoustic recordings to determine bird species richness},
journal={Ecological Applications},
year={2013},
month={2023/07/20/},
publisher={Ecological Society of America},
volume={23},
number={6},
pages={1419-1428},
abstract={[Acoustic sensors can be used to estimate species richness for vocal species such as birds. They can continuously and passively record large volumes of data over extended periods. These data must subsequently be analyzed to detect the presence of vocal species. Automated analysis of acoustic data for large numbers of species is complex and can be subject to high levels of false positive and false negative results. Manual analysis by experienced surveyors can produce accurate results; however the time and effort required to process even small volumes of data can make manual analysis prohibitive. This study examined the use of sampling methods to reduce the cost of analyzing large volumes of acoustic sensor data, while retaining high levels of species detection accuracy. Utilizing five days of manually analyzed acoustic sensor data from four sites, we examined a range of sampling frequencies and methods including random, stratified, and biologically informed. We found that randomly selecting 120 one-minute samples from the three hours immediately following dawn over five days of recordings, detected the highest number of species. On average, this method detected 62{\%} of total species from 120 one-minute samples, compared to 34{\%} of total species detected from traditional area search methods. Our results demonstrate that targeted sampling methods can provide an effective means for analyzing large volumes of acoustic sensor data efficiently and accurately. Development of automated and semi-automated techniques is required to assist in analyzing large volumes of acoustic sensor data.]},
note={Full publication date: September 2013},
issn={10510761},
url={http://www.jstor.org/stable/23596835}
}